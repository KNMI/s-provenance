from pymongo import *
import exceptions
import traceback
from prov.model import ProvDocument, Namespace, Literal, PROV, Identifier
import datetime
import uuid
import traceback
import os
import socket
import json
import httplib, urllib
import csv
import StringIO

 
def clean_empty(d):
    if not isinstance(d, (dict, list)):
        return d
    if isinstance(d, list):
        return [v for v in (clean_empty(v) for v in d) if v]
    return {k: v for k, v in ((k, clean_empty(v)) for k, v in d.items()) if v}

  
    

def toW3Cprov(prov,format='w3c-prov-json'):
        
        g = ProvDocument()
        vc = Namespace("verce", "http://verce.eu")  # namespaces do not need to be explicitly added to a document
        g.add_namespace("dcterms", "http://purl.org/dc/terms/")
        
        
        'specifing user'
        ag=g.agent(vc["ag_"+prov["username"]],other_attributes={"dcterms:author":prov["username"]})  # first time the ex namespace was used, it is added to the document automatically
        
        
        'specify bundle'
        
        if prov['type']=='workflow_run':
            
            prov.update({'runId':prov['_id']})
            dic={}
            i=0
            
            for key in prov:
                
                
                if key != "input": 
                    if ':' in key:
                        dic.update({key: prov[key]})
                    else:
                        dic.update({vc[key]: prov[key]})
                    
            
            dic.update({'prov:type': PROV['Bundle']})
            g.entity(vc[prov["runId"]], dic)
        else:   
            g.entity(vc[prov["runId"]], {'prov:type': PROV['Bundle']})
        
        g.wasAttributedTo(vc[prov["runId"]], vc["ag_"+prov["username"]],identifier=vc["run_"+prov["runId"]])
        bundle=g.bundle(vc[prov["runId"]])
        
        'specifing creator of the activity (to be collected from the registy)'
        
        if 'creator' in prov:
            bundle.agent(vc["ag_"+prov["creator"]],other_attributes={"dcterms:creator":prov["creator"]})  # first time the ex namespace was used, it is added to the document automatically
            bundle.wasAssociatedWith('process_'+prov["_id"],vc["ag_"+prov["creator"]])
            bundle.wasAttributedTo(vc[prov["runId"]], vc["ag_"+prov["creator"]])
    
    
    
        ' check for workflow input entities'
        if prov['type']=='workflow_run':
            dic={}
            i=0
            if type(prov['input'])!=list:
                prov['input']=[prov['input']]
                for y in prov['input']:
                    for key in y:
                        if ':' in key:
                            dic.update({key: y[key]})
                        else:
                            dic.update({vc[key]: y[key]})
                dic.update({'prov:type': 'worklfow_input'})
                bundle.entity(vc["data_"+prov["_id"]+"_"+str(i)], dic)
                bundle.wasGeneratedBy(vc["data_"+prov["_id"]+"_"+str(i)], identifier=vc["wgb_"+prov["_id"]+"_"+str(i)])
                
                 
                i=i+1
            if format=='w3c-prov-xml':
                return str(g.serialize(format='xml'))
            else:
                return json.loads(g.serialize(indent=4))
                
           
            
        
        
        'adding activity information for lineage'
        dic={}
        for key in prov:
            
            if type(prov[key])!=list:
                if ':' in key:
                    dic.update({key: prov[key]})
                else:
                    if key=='location':
                        
                        dic.update({"prov:location": prov[key]})    
                    else:
                        dic.update({vc[key]: prov[key]})
            
            
         
          
        bundle.activity(vc["process_"+prov["_id"]], prov["startTime"], prov["endTime"], dic.update({'prov:type': prov["name"]}))
        
        'adding parameters to the document as input entities'
        dic={}
        for x in prov["parameters"]:
            if ':' in x["key"]:
                dic.update({x["key"]: x["val"]})
            else:
                dic.update({vc[x["key"]]: x["val"]})
                
        dic.update({'prov:type':'parameters'})        
        bundle.entity(vc["parameters_"+prov["_id"]], dic)
        bundle.used(vc['process_'+prov["_id"]], vc["parameters_"+prov["_id"]], identifier=vc["used_"+prov["_id"]])

        'adding entities to the document as output metadata'
        for x in prov["streams"]:
            i=0
            parent_dic={}
            for key in x:
                    
                    
                    if key=='location':
                             
                        parent_dic.update({"prov:location": str(x[key])})    
                    else:
                        parent_dic.update({vc[key]: str(x[key])})    
            
            
            c1=bundle.collection(vc[x["id"]],other_attributes=parent_dic)
            bundle.wasGeneratedBy(vc[x["id"]], vc["process_"+prov["_id"]], identifier=vc["wgb_"+x["id"]])
            
            for d in prov['derivationIds']:
                    bundle.wasDerivedFrom(vc[x["id"]], vc[d['DerivedFromDatasetID']],identifier=vc["wdf_"+x["id"]])
        
            for y in x["content"]:
                
                dic={}
                
                if isinstance(y, dict):
                    val=None
                    for key in y:
                        
                        try: 
                            val =num(y[key])
                            
                        except Exception,e:
                            val =str(y[key])
                        
                        if ':' in key:
                            dic.update({key: val})
                        else:
                            dic.update({vc[key]: val})
                else:
                    dic={vc['text']:y}
                
                 
                dic.update({"verce:parent_entity": vc["data_"+x["id"]]})
                e1=bundle.entity(vc["data_"+x["id"]+"_"+str(i)], dic)
                
                bundle.hadMember(c1, e1)
                bundle.wasGeneratedBy(vc["data_"+x["id"]+"_"+str(i)], vc["process_"+prov["_id"]], identifier=vc["wgb_"+x["id"]+"_"+str(i)])
                
                for d in prov['derivationIds']:
                    bundle.wasDerivedFrom(vc["data_"+x["id"]+"_"+str(i)], vc[d['DerivedFromDatasetID']],identifier=vc["wdf_"+"data_"+x["id"]+"_"+str(i)])
        
                i=i+1
            
    
         
        
        if format=='w3c-prov-xml':
            return str(g.serialize(format='xml'))
        else:
            return json.loads(g.serialize(indent=4))

class ProvenanceStore(object):

    def __init__(self, url):
 
        self.conection = MongoClient(host=url)
        self.db = self.conection["verce-prov"]
        self.lineage = self.db['lineage']
        self.workflow = self.db['workflow']
        
        'too specific here, have to be migrated to gateway-api'
        self.solver = self.db['solver']
        
    'extract information about a list of workflow runs starting from start to limit'    
    
#suport for rest call on workflow resources 
    def getWorkflows(self,**kwargs):
    
        try:
            memory_file = StringIO.StringIO(kwargs['keys'][0]) if 'keys' in kwargs else None
            keylist = csv.reader(memory_file).next()
            memory_file = StringIO.StringIO(kwargs['maxvalues'][0]);
            maxvaluelist = csv.reader(memory_file).next()
            memory_file2 = StringIO.StringIO(kwargs['minvalues'][0]);
            minvaluelist = csv.reader(memory_file2).next()
            return self.getUserRunsValuesRange(kwargs['username'][0],keylist,maxvaluelist,minvaluelist,**kwargs)
  
        except Exception:
            traceback.print_exc()
            return self.getUserRuns(kwargs['username'][0],**kwargs)
        
#suport for rest call on entities resources         
    def getEntities(self,**kwargs):
        keylist=None
        maxvaluelist=None
        minvaluelist=None
        vluelist=None
        try:
            memory_file = StringIO.StringIO(kwargs['keys'][0]) if 'keys' in kwargs else None
            keylist = csv.reader(memory_file).next()
            memory_file = StringIO.StringIO(kwargs['maxvalues'][0]);
            maxvaluelist = csv.reader(memory_file).next()
            memory_file = StringIO.StringIO(kwargs['minvalues'][0]);
            minvaluelist = csv.reader(memory_file).next()
            memory_file = StringIO.StringIO(request.args['values'][0]) if 'values' in request.args else None
            vluelist = csv.reader(memory_file).next()
            return self.getEntitiesBy(kwargs['method'][0],keylist,maxvaluelist,minvaluelist,vluelist,**kwargs)
  
        except Exception:
            traceback.print_exc()
            return self.getEntitiesBy(kwargs['method'][0],keylist,maxvaluelist,minvaluelist,vluelist,**kwargs)
            
        
  
    def getEntitiesFilter(self,activ_searchDic,keylist,mxvaluelist,mnvaluelist,start,limit):
            elementsDict ={}
            #if iterationId!=None:
            
            if keylist==None:
                return self.lineage.find(activ_searchDic,{"runId":1,"streams":1,"parameters":1,'endTime':1,'errors':1})
            else:
                for x in keylist:
                    maxval=mxvaluelist.pop(0)
                    minval=mnvaluelist.pop(0)
                    try: 
                        maxval =self.num(maxval)
                        minval =self.num(minval)
                    except Exception,e:
                        None

                
                    elementsDict.update({x:{"$lte":maxval,"$gte":minval }})
                    searchDic={'streams.content':{'$elemMatch':elementsDict}}
                    #print elementsDict
                    activ_searchDic.update(searchDic)
                    
                    
                    #print str(activ_searchDic)
                    return self.lineage.find(activ_searchDic,{"runId":1,"streams.content.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1})[start:start+limit].sort("endTime",direction=-1)
                    #totalCount=totalCount+self.lineage.find(activ_searchDic,{"runId":1}).count()
                    
            
            
            
            
            
            
    
    
    def exportRunProvenance(self, id,**kwargs):
        
        
        
        
        
        totalCount=self.lineage.find({'runId':id}).count()
        cursorsList=list()
        
        if 'all' in kwargs and kwargs['all'][0].upper()=='TRUE':
            
            cursorsList.append(self.lineage.find({'runId':id})[int(kwargs['start'][0]):int(kwargs['start'][0])+int(kwargs['limit'][0])].sort("endTime",direction=-1))
             
        else:
            cursorsList.append(self.lineage.find({'runId':id})[int(kwargs['start'][0]):int(kwargs['start'][0])+int(kwargs['limit'][0])].sort("endTime",direction=-1))

        exportDocList = list()
        
        
        
        if ('start' in kwargs and int(kwargs['start'][0])==0) or ('all' in kwargs and kwargs['all'][0].upper()=='TRUE'):
            cursorsList.append(self.workflow.find({"_id":id}).sort("startTime",direction=-1)[0:totalCount])
        
        
        for cursor in cursorsList:    
            for x in cursor:
                if 'format' not in kwargs or kwargs['format'][0].find('w3c-prov')!=-1:
                    
                    exportDocList.append(toW3Cprov(x,format = kwargs['format'][0] if 'format' in kwargs else 'w3c-prov-json'))
        
        output = {"w3c-prov":exportDocList};
        output.update({"totalCount": totalCount})
      
        return  (output,totalCount)
    
    def exportAllRunProvenance(self, id,**kwargs):
        
        
        
        
        
        totalCount=self.lineage.find({'runId':id}).count()+1
        cursorsList=list()
        
        if ('start' in kwargs and int(kwargs['start'][0])==0):
            cursorsList.append(self.workflow.find({"_id":id}))
        
        
        if 'all' in kwargs and kwargs['all'][0].upper()=='TRUE':
            
            cursorsList.append(self.lineage.find({'runId':id})[int(kwargs['start'][0]):int(kwargs['start'][0])+int(kwargs['limit'][0])].sort("endTime",direction=-1))
             
        else:
            cursorsList.append(self.lineage.find({'runId':id})[int(kwargs['start'][0]):int(kwargs['start'][0])+int(kwargs['limit'][0])].sort("endTime",direction=-1))

        exportDocList = list()
        
        
        
        
        
        for cursor in cursorsList:    
            for x in cursor:
                if 'format' not in kwargs or kwargs['format'][0].find('w3c-prov')!=-1:
                    
                    exportDocList.append(toW3Cprov(x,format = kwargs['format'][0] if 'format' in kwargs else 'w3c-prov-json'))
        
        output = exportDocList
        
      
        return  (output,totalCount)
    
    def getSolverConf(self,path,request):
        try:
            solver = self.solver.find_one({"_id":path})
            if (solver!=None):
                solver.update({"success":True})
                userId = request.args["userId"][0] if "userId" in request.args else False
                def userFilter(item): return (not "users" in item) or (userId and userId in item["users"])
                def velmodFilter(item):
                    item["velmod"] = filter(userFilter, item["velmod"])
                    return item
                solver["meshes"] = map(velmodFilter, filter(userFilter, solver["meshes"]))
                return solver
            else:
                return {"success":False, "error":"Solver "+path+" not Found"}
            
        except Exception, e:
            return {"success":False, "error":str(e)}
    
    
    
    
    
    
    def getUserRunsValuesRange(self,userid,keylist,maxvaluelist,minvaluelist,**kwargs):
        elementsDict ={}
        output=None
        runids=[]
        uniques=None
        
        start=int(kwargs['start'][0])
        limit=int(kwargs['limit'][0])
        if keylist==None: 
            keylist=[]
        
        if 'activities' in kwargs:
            #print str(kwargs)
            values=str(kwargs['activities'][0]).split(',')
            intersect=False
            for y in values:
                uniques_act=self.lineage.find({'username':userid,'name':y}).distinct("runId")[start:start+limit]
                if intersect==True:
                    uniques=list(set(uniques).intersection(set(uniques_act)))
                else:
                    uniques=uniques_act
                    intersect=True
                
            
        
        if len(keylist)!=0 and "mime-type" in keylist:
            values=list((set(minvaluelist).union(set(maxvaluelist))))
            uniques_mime=self.lineage.find({'username':userid,'streams.format':{'$in':values}}).distinct("runId")[start:start+limit]
            
            i = keylist.index('mime-type')
            minvaluelist.pop(i)
            maxvaluelist.pop(i)
            keylist.remove('mime-type')
            
            if uniques!=None:
                uniques=list(set(uniques).intersection(set(uniques_mime)))
            else:
                uniques=uniques_mime
            
        
        for x in keylist:
            maxval=maxvaluelist.pop(0)
            minval=minvaluelist.pop(0)
            try: 
                maxval =self.num(maxval)
                minval =self.num(minval)
            except Exception,e:
                None
            
            objdata=self.lineage.find({'username':userid,'streams.content':{'$elemMatch':{x:{"$lte":maxval,"$gte":minval }}}}).distinct("runId")[start:start+limit]
            objpar=self.lineage.find({'username':userid,'parameters':{'$elemMatch':{'key':x,'val':{"$lte":maxval,"$gte":minval }}}}).distinct("runId")[start:start+limit]            
            
            object_union=list(set(objdata).union(set(objpar)))
            
             
            
            if uniques!=None:
                 
                uniques=list(set(uniques).intersection(set(object_union)))
                 
            else:
                uniques=object_union
                
            
       
        totalCount=len(uniques)
        
        #print str(uniques)
        obj=self.workflow.find({"_id":{"$in":uniques}},{"startTime":-1,"system_id":1,"description":1,"name":1,"workflowName":1,"grid":1,"resourceType":1,"resource":1,"queue":1}).sort("startTime",direction=-1)[start:start+limit]
         
        for x in obj:
            
            runids.append(x)
        
            
        output = {"runIds":runids};
        output.update({"totalCount": totalCount})
        
        return output
    
    
    def getEntitiesByValuesRange(self,path,keylist,mtype,start,limit,runId=None,iterationId=None,dataId=None,maxvaluelist=None,minvaluelist=None,valuelist=None):
         
        elementsDict ={}
        output=None
        runids=[]
        uniques=None
       
        for x in keylist:
            maxval=maxvaluelist.pop(0)
            minval=minvaluelist.pop(0)
            try: 
                maxval =self.num(maxval)
                minval =self.num(minval)
            except Exception,e:
                None
             
            if runId!=None:
                
                objdata=self.lineage.find({'runId':runId,'streams.format':mtype,'streams.content':{'$elemMatch':{x:{"$lte":maxval,"$gte":minval }}}},{"runId":1,"streams.content.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1}) 
                objpar=self.lineage.find({'runId':runId,'streams.format':mtype,'parameters':{'$elemMatch':{'key':x,'val':{"$lte":maxval,"$gte":minval }}}},{"runId":1,"streams.content.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1}) 
                
                object_union=list(set(objdata).union(set(objpar)))
                
                
            else:
                
                objdata=self.lineage.find({'runId':runId,'streams.format':mtype,'streams.content':{'$elemMatch':{x:{"$lte":maxval,"$gte":minval }}}},{"runId":1,"streams.content.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1}) 
                objpar=self.lineage.find({'runId':runId,'streams.format':mtype,'parameters':{'$elemMatch':{'key':x,'val':{"$lte":maxval,"$gte":minval }}}},{"runId":1,"streams.content.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1})            
                object_union=list(set(objdata).union(set(objpar)))
                
            if (uniques!=None):
                uniques=list(set(uniques).intersection(set(object_union)))
                
            else:
           
                uniques=object_union
                
        
        totalCount=len(uniques)
          
        
               
        
        
                    
        artifacts = list()

        
        for x in  uniques:
            
            for s in x["streams"]:
                totalCount=totalCount+1
                s["wasGeneratedBy"]=x["_id"]
                s["parameters"]=x["parameters"]
                s["endTime"]=x["endTime"]
                s["runId"]=x["runId"]
                s["errors"]=x["errors"]
                artifacts.append(s)
                    
        
                
        output = {"entities":artifacts};
        output.update({"totalCount": totalCount})
        return  output
        
        
    
    def getRunInfo(self, path):
        
         obj = self.workflow.find_one({"_id":path})
         return obj

         
     
    def getUserRuns(self, path, **kwargs):
        
        
        obj=None
        totalCount=None
        output=None
        start=int(kwargs['start'][0])
        limit=int(kwargs['limit'][0])
        
        
        if 'activities' in kwargs:
            return self.getUserRunsValuesRange(kwargs['username'][0],None,None,None,**kwargs)
        else:
            obj = self.workflow.find({"username":path},{"_id":-1,"startTime":-1,"system_id":1,"description":1,"name":1,"workflowName":1,"grid":1,"resourceType":1,"resource":1,"queue":1}).sort("startTime",direction=-1)[start:start+limit]

        totalCount=self.workflow.find({"username":path}).count()
        runids = list()
        
        for x in obj:
                
            runids.append(x)
            
        output = {"runIds":runids};
        output.update({"totalCount": totalCount})
    
        return  output
    
    
    def num(self,s):
        try:
            return int(s)
        except exceptions.ValueError:
            return float(s)

     
    
    
    def getEntitiesBy(self,method,keylist,mxvaluelist,mnvaluelist,vluelist,**kwargs):
        totalCount=0;
        cursorsList=list()
        obj=None
        
        start=int(kwargs['start'][0]) if 'start' in kwargs else None
        limit=int(kwargs['limit'][0]) if 'limit' in kwargs else None
        runId=kwargs['runId'][0] if 'runId' in kwargs else None
        dataId=kwargs['dataId'][0] if 'dataId' in kwargs else None
        iterationId=kwargs['iterationId'][0] if 'iterationId' in kwargs else None
        mtype=kwargs['mime-type'][0] if 'mime-type' in kwargs else None
        activities=None
        
        if 'activities' in kwargs:
            activities=str(kwargs['activities'][0]).split(',')
            
        i=0
        ' extract data by annotations either from the whole archive or for a specific runId'
         
        activ_searchDic={'_id':iterationId,'name':{'$in':activities},'runId':runId,'streams.format':mtype}
        activ_searchDic=clean_empty(activ_searchDic)
        #print activ_searchDic
    
        
        
        if method=="annotations":
            if runId!=None:
                for x in keylist:
                    cursorsList.append(self.lineage.find({'streams.annotations':{'$elemMatch':{'key': x,'val':{'$in':vluelist}}},'runId':runId},{"runId":1,"streams.annotations.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1,})[start:start+limit].sort("endTime",direction=-1))
                    totalCount = totalCount + self.lineage.find({'streams.annotations':{'$elemMatch':{'key': x,'val':{'$in':vluelist}}},'runId':runId},).count()
            else:
                for x in keylist:
                    cursorsList.append(self.lineage.find({'streams.annotations':{'$elemMatch':{'key': x,'val':{'$in':vluelist}}}},{"runId":1,"streams.annotations.$":1,'streams':1,'endTime':1,'errors':1,"parameters":1})[start:start+limit].sort("endTime",direction=-1))
                    totalCount = totalCount + self.lineage.find({'streams.annotations':{'$elemMatch':{'key': x,'val':{'$in':vluelist}}}},).count()
        
        if method=="generatedby":
            cursorsList.append(self.getEntitiesFilter(activ_searchDic,keylist,mxvaluelist,mnvaluelist,start,limit))
        elif method=="run":        
            cursorsList.append(self.lineage.find({'runId':runId,'streams.id':dataId},{"runId":1,"streams":{"$elemMatch": { "id": dataId}},"parameters":1,'endTime':1,'errors':1}))
            totalCount = totalCount + self.lineage.find({'runId':runId,'streams.id':dataId}).count()
        elif method=="values-range":
            cursorsList.append(self.getEntitiesFilter(activ_searchDic,keylist,mxvaluelist,mnvaluelist,start,limit))
        
        else:
            cursorsList.append(self.lineage.find({'streams.id':method},{"runId":1,"streams":{"$elemMatch": { "id": method}},"parameters":1,'endTime':1,'errors':1}))
                
            
        artifacts = list()

        for cursor in cursorsList:
            for x in cursor:
                
                for s in x["streams"]:
                     
                    if (mtype==None or mtype=="") or (s["format"]==mtype):
                        totalCount=totalCount+1
                        s["wasGeneratedBy"]=x["_id"]
                        s["parameters"]=x["parameters"]
                        s["endTime"]=x["endTime"]
                        s["runId"]=x["runId"]
                        s["errors"]=x["errors"]
                        artifacts.append(s)
                    
        
                
        output = {"entities":artifacts};
        output.update({"totalCount": totalCount})
        return  output
         
    def getActivities(self, id,start,limit):
        obj = self.lineage.find({'runId':id},{"runId":1,"instanceId":1,"parameters":1,"endTime":-1,"errors":1,"iterationIndex":1})[start:start+limit].sort("endTime",direction=-1)
        totalCount=self.lineage.find({'runId':id},{"instanceId":1}).count()
        activities = list()
        
        for x in obj:
            activities.append(x)
        output = {"activities":activities};
        output.update({"totalCount": totalCount})
        return  output
    
    def editRun(self, id,doc):
        ret=[]
        response={}
        
        try:
            
            self.workflow.update({"_id":id},{'$set':doc})
        
            response={"success":True}
            response.update({"edit":id}) 
        
        except Exception, err:
            response={"success":False}
            response.update({"error":str(err)})
            traceback.print_exc()
        finally:
            return response
        
        
    def deleteRun(self, id):
        ret=[]
        response={}
        
        try:
            if (self.workflow.find_one({"_id":id})!=None):
                self.lineage.remove({"runId":id})
                self.workflow.remove({"_id":id})
            
                response={"success":True}
                response.update({"delete":id}) 
            else:
                response={"success":False}
                response.update({"error":"Workflow run "+id+" does not exist!"}) 
            
        except Exception, err:
            response={"success":False}
            response.update({"error":str(err)})
            traceback.print_exc()
        finally:
            return response
    
    def insertWorkflow(self, json):
        ret=[]
        response={}
        
        try:
            if type(json) =='list':
        
                for x in json:
                    
                    ret.append(self.workflow.insert(x))
            else:
                ret.append(self.workflow.insert(json))
        
            response={"success":True}
            response.update({"inserts":ret}) 
        
        except Exception, err:
            response={"success":False}
            response.update({"error":str(err)}) 
        finally:
            return response
    
    
    ' insert new data in different collections depending from the document type'

    def updateCollections(self, prov):
        try:
            if prov["type"]=="lineage":
                if prov["type"]=="lineage":
                    return self.lineage.insert(prov)
                # if(self.workflow.find_one({"_id":prov["runId"]})!=None):
                #     return self.lineage.insert(prov)
                # else: 
                #     raise Exception("Workflow Run not found")

            if prov["type"]=="workflow_run":
             
                return self.workflow.insert(prov)
        
        except Exception, err:
            raise
            
    def insertData(self, prov):
        ret=[]
        response={}
        
        
        try:
            if type(prov).__name__ =='list':
                 
                for x in prov:
                   try:
                       ret.append(self.updateCollections(x))
                   except Exception, err:
                       ret.append({"error":str(err)})
            else:
                try:
                 
                    ret.append(self.updateCollections(prov))
                except Exception, err:
                       ret.append({"error":str(err)})
        
            response={"success":True}
            response.update({"inserts":ret}) 
        
        except Exception, err:
            
            response={"success":False}
            response.update({"error":str(err)}) 
            
        finally:
            return response
    
    
    def getDerivedDataTrace(self, id,level):
         
        xx = self.lineage.find_one({"streams.id":id},{"runId":1});
        xx.update({"dataId":id})
        cursor=self.lineage.find({"derivationIds":{'$elemMatch':{"DerivedFromDatasetID":id}}},{"runId":1,"streams":1});
         
        
        if level>0:
            derivedData=[]
            
            i=0
            for d in cursor:
                i+=1
                if (i<25):
                 
                 
                 
                    for str in d["streams"]:
                     
                        try:
                            derivedData.append(self.getDerivedDataTrace(str["id"],level-1))
                        
                        except Exception, err:
                            None
                 
                 
                
            xx.update({"derivedData":derivedData})
                
            
         
        
      
        return xx
        
    def getTrace(self, id,level):
         
        xx = self.lineage.find_one({"streams.id":id},{"runId":1,"derivationIds":1});
         
         
        xx.update({"id":id})
        if level>=0:
            for derid in xx["derivationIds"]:
                try:
                    derid["wasDerivedFrom"] = self.getTrace(derid["DerivedFromDatasetID"],level-1)
                except Exception, err:
                    None
            return xx
        
    
    
    def filterOnAncestorsValuesRange(self,idlist,keylist,minvaluelist,maxvaluelist):
        filteredIds=[]
        for x in idlist:
            test=self.hasAncestorWithValuesRange(x,keylist,minvaluelist,maxvaluelist)
         #   print test
            if test["hasAncestorWith"]==True:
                filteredIds.append(x)
        
        return filteredIds
    
    def filterOnAncestorsMeta(self,idlist,keylist,valuelist):
        filteredIds=[]
        for x in idlist:
            test=self.hasAncestorWith(x,keylist,valuelist)
         #   print test
            if test["hasAncestorWith"]==True:
                filteredIds.append(x)
        
        return filteredIds
    
    def filterOnMeta(self,idlist,keylist,valuelist):
        filteredIds=[]
        for x in idlist:
            test=self.hasMeta(x,keylist,valuelist)
        #   print test
            if test["hasMeta"]==True:
                filteredIds.append(x)
        
        return filteredIds
            
    
    def hasMeta(self, id, keylist,valuelist):
         
        elementsDict ={}
        
        k=0
        for x in keylist:
            val=valuelist[k]
            k+=1
            try: 
                val =self.num(val)
            except Exception,e:
                None

            elementsDict.update({x:val})
        
        xx = self.lineage.find_one({"streams":{"$elemMatch":{"id":id,'content':{'$elemMatch':elementsDict}}}},{"streams.id":1});
        if (xx!=None):    
            
            return {"hasMeta":True}
                    
                  
        else:
            return {"hasMeta":False}
    
                
    def hasAncestorWithValuesRange(self, id, keylist,minvaluelist,maxvaluelist):
         
        elementsDict ={}
        k=0
        for x in keylist:
            maxval=maxvaluelist[k]
            minval=minvaluelist[k]
            k+=1
            try: 
                maxval =self.num(maxval)
                minval =self.num(minval)
            except Exception,e:
                None
                

            elementsDict.update({x:{"$lte":maxval,"$gte":minval }})
        
        xx = self.lineage.find_one({"streams.id":id},{"runId":1,"derivationIds":1});
        if len(xx["derivationIds"])>0:    
            for derid in xx["derivationIds"]:
                try:
                #    print derid["DerivedFromDatasetID"]
                    anchestor = self.lineage.find_one({"streams":{"$elemMatch":{"id":derid["DerivedFromDatasetID"],'content':{'$elemMatch':elementsDict}}}},{"streams.id":1});
                    
                    if anchestor!=None:
                        return {"hasAncestorWith":True}
                    else:
                        return self.hasAncestorWithValuesRange(derid["DerivedFromDatasetID"],keylist,minvaluelist,maxvaluelist)
                except Exception,e: 
                   traceback.print_exc()
        else:
            return {"hasAncestorWith":False}
        
    
    def hasAncestorWith(self, id, keylist,valuelist):
         
        elementsDict ={}
        
        k=0
        for x in keylist:
            val=valuelist[k]
            k+=1
            try: 
                val =self.num(val)
            except Exception,e:
                None

            elementsDict.update({x:val})
        
        xx = self.lineage.find_one({"streams.id":id},{"runId":1,"derivationIds":1});
        if len(xx["derivationIds"])>0:    
            for derid in xx["derivationIds"]:
                try:
                #    print derid["DerivedFromDatasetID"]
                    anchestor = self.lineage.find_one({"streams":{"$elemMatch":{"id":derid["DerivedFromDatasetID"],'content':{'$elemMatch':elementsDict}}}},{"streams.id":1});
                    
                    if anchestor!=None:
                        return {"hasAncestorWith":True}
                    else:
                        return self.hasAncestorWith(derid["DerivedFromDatasetID"],keylist,valuelist)
                except Exception,e: 
                   traceback.print_exc()
        else:
            return {"hasAncestorWith":False}
       
        
        
    def getTraceConditonalX(self, id, keylist,valuelist):
         
        elementsDict ={}
        
        k=0
        for x in keylist:
            val=valuelist[k]
            k+=1
            try: 
                val =self.num(val)
            except Exception,e:
                None

            elementsDict.update({x:val})
        
        xx = self.lineage.find_one({"streams.id":id,'streams.content':{'$elemMatch':elementsDict}},{"runId":1,"derivationIds":1});
        
        if xx==None:
            xx = self.lineage.find_one({"streams.id":id},{"runId":1,"derivationIds":1});
             
            xx.update({"id":id})
            
            for derid in xx["derivationIds"]:
                try:
                    val = self.getTraceConditonal(derid["DerivedFromDatasetID"],keylist,valuelist)
                     
                    if val!=None:
                        return {"hasAnchestor":True}
                    
                except Exception, err:
                    traceback.print_exc()
            
        else:
            return xx
